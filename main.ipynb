{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "dataset = load_dataset(\"NTTUNLPTEAM/class-textbook\",split='train')\n",
    "format_func = lambda data: f\"text: {data['text']}, metadata: {data['metadata']}, type: {data['type']}, summary: {data['summary']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.028497308492660522,\n",
       " 0.08764791488647461,\n",
       " -0.02262119948863983,\n",
       " -0.07729446142911911,\n",
       " -0.09653183072805405]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model='all-minilm')\n",
    "text = 'hello world'\n",
    "\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts('test',embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_text(format_func(dataset))\n",
    "\n",
    "# if os.path.exists(\"./dataset/faiss_db\"):\n",
    "vectorstore = FAISS.from_texts(texts=splits, embedding=OllamaEmbeddings(model='all-minilm'))\n",
    "vectorstore.save_local(\"faiss-index\")\n",
    "newvector = FAISS.load_local(\"faiss-index\",embeddings,allow_dangerous_deserialization=True)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = newvector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"gpt2\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\": 100}\n",
    "# )\n",
    "\n",
    "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# model_id = \"gpt2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=10)\n",
    "# hf = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama()\n",
    "llm.invoke(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join( doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下是基於提供的上下文的十個問題： \\n\\n 1.“醫院感染”一詞是什麼意思是什麼？醫院感染的兩種一般類型是什麼？ \\n 2.命名病原體進入人體的五個潛在入口。 \\n 3.傳染病和傳染性疾病有什麼區別？ \\n 4.解釋巴氏滅菌和滅菌之間的差異。 \\n 5.描述病毒的結構及其如何引起疾病。 \\n 6.命名人體病原體的五個潛在出口門戶。 \\n 7.什麼是酵母和黴菌，它們彼此之間有何不同？ \\n 8.描述表面和全身mycoses之間的差異。 \\n 9.什麼是緩衝系統，如何限制pH的巨大變化？ \\n 10.命名一些由向量傳播的疾病，並為每個疾病命名矢量。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = rag_chain.invoke(\"give me a summary of the text and generate ten questions\")\n",
    "\n",
    "import translators as ts\n",
    "ts.translate_text(query_text=ans, translator='google', from_language= 'en', to_language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are ten questions based on the provided context:\n",
      "\n",
      "1. What does the term \"nosocomial infection\" refer to, and what are the two general types of nosocomial infections?\n",
      "2. Name five potential portals of entry for pathogens into the human body.\n",
      "3. What is the difference between a communicable disease and a contagious disease?\n",
      "4. Explain the difference between pasteurization and sterilization.\n",
      "5. Describe the structure of a virus and how it causes disease.\n",
      "6. Name five potential portals of exit for pathogens from the human body.\n",
      "7. What are yeasts and molds, and how do they differ from each other?\n",
      "8. Describe the differences between superficial and systemic mycoses.\n",
      "9. What is a buffer system, and how does it limit great changes in pH?\n",
      "10. Name some diseases that are spread by vectors, and name the vector for each.\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "病原體進入人體的五個潛在入口是： \n",
      "\n",
      " 1.鼻腔：病原體可以通過鼻子進入身體，尤其是通過鼻腔中的粘膜進入身體。 \n",
      " 2.口：病原體可以通過攝入污染的食物或水或直接與皮膚接觸來通過口腔進入身體。 \n",
      " 3.皮膚：病原體可以通過皮膚斷裂進入身體，例如切割，刮傷或傷口。 \n",
      " 4.眼睛：病原體可以通過眼睛進入身體，尤其是通過暴露於污染的水或觸摸受污染的表面然後觸摸臉部的情況。 \n",
      " 5.泌尿生殖道：病原體可以在性接觸期間通過泌尿生殖道進入身體，或通過暴露於污染的水或土壤中。\n"
     ]
    }
   ],
   "source": [
    "ans = rag_chain.invoke(\"Name five potential portals of entry for pathogens into the human body.\")\n",
    "print(ts.translate_text(query_text=ans, translator='google', from_language= 'en', to_language='zh-TW'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
